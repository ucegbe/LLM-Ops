{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867a728-5d84-4ad2-8160-6a367153884c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade sagemaker datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee878106-30f6-4367-875e-e284222166ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "import boto3 \n",
    "import pandas as pd \n",
    "import sagemaker \n",
    "from sagemaker.workflow.pipeline_context import PipelineSession \n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "s3_client = boto3.resource('s3') \n",
    "pipeline_name = f\"Llama2-Mlops\" \n",
    "sagemaker_session = sagemaker.session.Session() \n",
    "region = sagemaker_session.boto_region_name \n",
    "role = sagemaker.get_execution_role() \n",
    "pipeline_session = PipelineSession() \n",
    "default_bucket = \"BUCKET\"#sagemaker_session.default_bucket() \n",
    "\n",
    "\n",
    "from sagemaker.workflow.parameters import ( \n",
    " ParameterInteger, \n",
    " ParameterString, \n",
    " ParameterFloat,\n",
    "ParameterBoolean) \n",
    "\n",
    "training_instance_count = ParameterInteger(name=\"TrainingInstanceCount\", default_value=1)\n",
    "endpoint_instance_type = ParameterString( name=\"EndpointInstanceType\", default_value=\"ml.g5.2xlarge\") \n",
    "training_instance_type = ParameterString( name=\"TrainingInstanceType\", default_value=\"ml.g5.12xlarge\") \n",
    "disable_output_compression = ParameterBoolean( name=\"OutputCompression\", default_value=False) \n",
    "intstruction_tune = ParameterString( name=\"IntsructionTune\", default_value=\"False\",enum_values=[\"False\",\"True\"]) \n",
    "chat_dataset = ParameterString( name=\"ChatDataset\", default_value=\"False\",enum_values=[\"False\",\"True\"]) \n",
    "epoch = ParameterString( name=\"Epoch\", default_value=\"1\") \n",
    "quantization = ParameterString( name=\"Int8Quant\", default_value=\"False\",enum_values=[\"False\",\"True\"]) \n",
    "fsdp = ParameterString( name=\"FSDP\", default_value=\"True\",enum_values=[\"False\",\"True\"])  \n",
    "train_batch_size = ParameterString( name=\"TrainBatchSize\", default_value=\"4\") \n",
    "eval_batch_size = ParameterString( name=\"EvalBatchSize\", default_value=\"1\") \n",
    "learning_rate = ParameterString( name=\"LearningRate\", default_value=\"0.0001\") \n",
    "lora_r = ParameterString( name=\"LoraR\", default_value=\"8\") \n",
    "lora_alpha = ParameterString( name=\"LoraAlpha\", default_value=\"32\") \n",
    "lora_dropout = ParameterString( name=\"LoraDropout\", default_value=\"0.05\") \n",
    "train_data_s3_path=ParameterString( name=\"TrainDataS3Path\", default_value=None)\n",
    "val_data_s3_path=ParameterString( name=\"ValidationDataS3Path\", default_value=None)\n",
    "stereotype_data_s3_path=ParameterString( name=\"StereotypeDataS3Path\", default_value=None)\n",
    "stereotype_dataset_name=ParameterString( name=\"StereotypeDataName\", default_value=None)\n",
    "model_approval_status = ParameterString( name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\")\n",
    "output_bucket = ParameterString( name=\"Bucket\", default_value=\"calibucket-aws\")\n",
    "model_package_group_name = ParameterString( name=\"ModelPackageGroupName\", default_value=None)\n",
    "jumpstart_model_id = ParameterString( name=\"JumpStartModelID\", default_value=\"meta-textgeneration-llama-2-7b-f\")\n",
    "jumpstart_model_version = ParameterString( name=\"JumpStartModelVersion\", default_value=\"*\")\n",
    "model_card_name = ParameterString( name=\"ModelCardName\", default_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c74a6-68d0-450a-840a-96684f17d212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"meta-textgeneration-llama-2-7b-f\"\n",
    "model_version = \"3.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e43d062-b3b8-41d4-90dd-99f18a3bcb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "estimator = JumpStartEstimator(\n",
    "                               model_id=model_id, \n",
    "                               model_version=model_version,\n",
    "                               environment={\"accept_eula\": \"true\",\n",
    "                                            \"SageMakerGatedModelS3Uri\": \"s3://jumpstart-private-cache-prod-us-east-1/meta-training/g5/v1.0.0/train-meta-textgeneration-llama-2-7b-f.tar.gz\"\n",
    "                                           },\n",
    "                                image_uri=\"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\",\n",
    "                               instance_type = training_instance_type,\n",
    "                               instance_count=training_instance_count,\n",
    "                              sagemaker_session=PipelineSession(),\n",
    "                               # base_job_name=\"llama2-finance-tuning\",\n",
    "                               keep_alive_period_in_seconds=3600,\n",
    "                               disable_output_compression=False,\n",
    "                               enable_sagemaker_metrics=True\n",
    "                              )\n",
    "estimator.set_hyperparameters(instruction_tuned=intstruction_tune, \n",
    "                              epoch=epoch,\n",
    "                              chat_dataset=chat_dataset,\n",
    "                              int8_quantization=quantization,\n",
    "                              learning_rate=learning_rate,\n",
    "                              lora_alpha=lora_alpha,\n",
    "                              lora_dropout=lora_dropout,\n",
    "                              lora_r=lora_r,\n",
    "                              per_device_eval_batch_size=train_batch_size,\n",
    "                              per_device_train_batch_size=eval_batch_size,\n",
    "                              enable_fsdp=fsdp                           \n",
    "                             )\n",
    "train_args=estimator.fit({\"training\": train_data_s3_path,#f\"s3://jumpstart-cache-prod-us-east-1/training-datasets/sec_data/train/\",\n",
    "                         \"validation\":val_data_s3_path #\"s3://jumpstart-cache-prod-us-east-1/training-datasets/sec_data/validation/\"\n",
    "                         }, \n",
    "                         wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37047f05-9386-4097-9824-a06de3ec44c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_train = TrainingStep(\n",
    "    name=\"Llama2Tuning\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e2b33-d43b-4161-9e40-a19021fb49e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "llm_image = get_huggingface_llm_image_uri(\"huggingface\", version=\"1.1.0\")\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "   role=role,  \n",
    "    image_uri=llm_image,   \n",
    "   sagemaker_session=pipeline_session,\n",
    "   env= {\"ENDPOINT_SERVER_TIMEOUT\": \"3600\",\n",
    "            \"HF_MODEL_ID\": \"/opt/ml/model\",\n",
    "            \"MAX_INPUT_LENGTH\": \"4095\",\n",
    "            \"MAX_TOTAL_TOKENS\": \"4096\",\n",
    "            \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
    "            \"SAGEMAKER_ENV\": \"1\",\n",
    "            \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
    "            \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
    "            \"SM_NUM_GPUS\": \"1\"}     \n",
    ")\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"Llama2FinanaceTunedModel\",\n",
    "    step_args=huggingface_model.create(instance_type=endpoint_instance_type)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f09010c-03aa-483a-8b68-83332c5db3ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import Model\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "register_args = huggingface_model.register(\n",
    "    content_types=[\"aplication/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[endpoint_instance_type],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    ")\n",
    "step_register = ModelStep(name=\"Llama2FinetunedRegisterModel\", step_args=register_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca53602-d7ea-4e61-8096-8db34f524e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile lambda_deployer.py\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "def lambda_handler(event, context):\n",
    "    sm_client=boto3.client(\"sagemaker\")\n",
    "    # The name of the model created in the Pipeline CreateModelStep\n",
    "    model_name = event[\"model_name\"]\n",
    "    endpoint_config_name = event[\"endpoint_config_name\"]\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    role = event[\"role\"] \n",
    "\n",
    "\n",
    "    create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"InstanceType\": \"ml.g5.2xlarge\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"ModelName\": model_name,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "    time.sleep(120)\n",
    "    create_endpoint_response = sm_client.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Created Endpoint\"),\n",
    "        \"other_key\": \"example_value\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2c852-b1b9-4efb-b694-f3da36b5900c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the current time to define unique names for the resources created\n",
    "import time\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "\n",
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
    "\n",
    "model_name = step_create_model.properties.ModelName\n",
    "endpoint_config_name = \"Llama2Tuned\" + current_time\n",
    "endpoint_name = \"Llama2Tuned\" + current_time\n",
    "function_name = \"sagemaker-deploy\" + current_time\n",
    "lambda_role=\"arn:aws:iam::259508681668:role/FullLambdaJobAccess\"\n",
    "# Lambda helper class can be used to create the Lambda function\n",
    "func = Lambda( \n",
    "    function_name=function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"lambda_deployer.py\",\n",
    "    handler=\"lambda_deployer.lambda_handler\",\n",
    "    timeout=600,\n",
    "    memory_size=10240,\n",
    "    runtime='python3.10'\n",
    ")\n",
    "\n",
    "# The dictionary retured by the Lambda function is captured by LambdaOutput, each key in the dictionary corresponds to a\n",
    "# LambdaOutput\n",
    "\n",
    "output_param_1 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_3 = LambdaOutput(output_name=\"other_key\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "# The inputs provided to the Lambda function can be retrieved via the `event` object within the `lambda_handler` function\n",
    "# in the Lambda\n",
    "step_deploy_lambda = LambdaStep(\n",
    "    name=\"LambdaStepHuggingFaceDeploy\",\n",
    "    lambda_func=func,\n",
    "    inputs={\n",
    "        \"model_name\": model_name,       \n",
    "        \"endpoint_config_name\": endpoint_config_name,\n",
    "        \"endpoint_name\": endpoint_name,        \n",
    "        \"role\": role,  \n",
    "    },\n",
    "    outputs=[output_param_1, output_param_2, output_param_3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76dd17d-c615-496b-8f30-f04f4d75e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile llm_eval.py\n",
    "\n",
    "def llama_evaluation(data_path, endpoint_name):\n",
    "    from fmeval.data_loaders.data_config import DataConfig\n",
    "    from fmeval.model_runners.sm_jumpstart_model_runner import JumpStartModelRunner\n",
    "    from fmeval.constants import MIME_TYPE_JSONLINES\n",
    "    from fmeval.eval_algorithms.prompt_stereotyping import PromptStereotyping\n",
    "    model_version = \"3.*\"\n",
    "    model_id = \"meta-textgeneration-llama-2-7b-f\"\n",
    "\n",
    "    config = DataConfig(\n",
    "        dataset_name=\"crows-pairs_sample\",\n",
    "        dataset_uri=data_path,\n",
    "        dataset_mime_type=MIME_TYPE_JSONLINES,\n",
    "        sent_more_input_location=\"sent_more\",\n",
    "        sent_less_input_location=\"sent_less\",\n",
    "        category_location=\"bias_type\",\n",
    "    )\n",
    "\n",
    "    js_model_runner = JumpStartModelRunner(\n",
    "        endpoint_name=endpoint_name,\n",
    "        model_id=model_id,\n",
    "        model_version=model_version,\n",
    "        output='[0].generated_text',\n",
    "        log_probability='[0].details.prefill[*].logprob',\n",
    "        content_template='{\"inputs\": $prompt, \"parameters\": {\"top_p\": 0.9, \"temperature\": 0.85, \"max_new_tokens\": 1024, \"return_full_text\":false,\"decoder_input_details\": true,\"details\": true }}',\n",
    "\n",
    "        custom_attributes=\"accept_eula=true\",\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    eval_algo = PromptStereotyping()\n",
    "    eval_output = eval_algo.evaluate(model=js_model_runner, dataset_config=config, prompt_template=\"$feature\", save=True)\n",
    "\n",
    "    return eval_output\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "subprocess.run([\"pip\", \"install\", \"pip\", \"-U\"])\n",
    "subprocess.run([\"pip\", \"install\", \"sagemaker\"])\n",
    "subprocess.run([\"pip\", \"install\", \"fmeval\"])\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "import boto3\n",
    "sage=boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--dataset-name\", type=str)\n",
    "parser.add_argument(\"--endpoint-name\", type=str)\n",
    "# parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "eval_dir = \"stereotyping\"\n",
    "curr_dir = \"opt/ml/output\"#args.train\n",
    "# eval_results_path = os.path.join(curr_dir, eval_dir) + \"/\"\n",
    "os.environ[\"EVAL_RESULTS_PATH\"] = curr_dir\n",
    "# if os.path.exists(eval_results_path):\n",
    "#     print(f\"Directory '{eval_results_path}' exists.\")\n",
    "# else:\n",
    "#     os.mkdir(eval_results_path)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "endpoint_name=args.endpoint_name\n",
    "dataset_name=args.dataset_name\n",
    "\n",
    "status=sage.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")['EndpointStatus']\n",
    "while status != 'InService':\n",
    "    status=sage.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    "    )['EndpointStatus']\n",
    "\n",
    "data_path=f\"/opt/ml/input/data/training/{dataset_name}\"\n",
    "result=llama_evaluation(data_path, endpoint_name)\n",
    "with open(f\"/opt/ml/output/data/eval_metrics.json\",\"w\") as f:\n",
    "    json.dump(result,f, default=vars, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae57fda6-745e-4b7a-87fc-857e6bda13e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "\n",
    "\n",
    "eval_processor = PyTorch(\n",
    "    role=role, instance_type=\"ml.m5.xlarge\", instance_count=1,\n",
    "    entry_point=\"llm_eval.py\",  \n",
    "    image_uri=img,\n",
    "    hyperparameters={\n",
    "        \"dataset-name\":stereotype_dataset_name,\n",
    "                    \"endpoint-name\": endpoint_name},\n",
    "    keep_alive_period_in_seconds=3600,\n",
    "    sagemaker_session=PipelineSession(),\n",
    ")\n",
    "\n",
    "process_args=eval_processor.fit({\"training\":stereotype_data_s3_path})\n",
    "step_process = TrainingStep(\n",
    "    name=\"Llama2EvaluateStereotype\",\n",
    "    step_args=process_args,\n",
    "    depends_on = [step_deploy_lambda]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ee45d-374e-4696-ad1a-bf823b9b3a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile lambda_model_card.py\n",
    "\n",
    "\"\"\"\n",
    "This Lambda function creates a model card for the fine-tuned model\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "def _create_model_card(file,event):\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "    file['model_overview']['model_name']=event['model_name']\n",
    "    file['model_overview']['model_id']=event[\"model_arn\"]\n",
    "    file['model_overview']['model_artifact']=[event['model_artifact']]\n",
    "    file['model_overview']['problem_type']=\"\"\n",
    "    file['model_overview']['algorithm_type']=\"NeuralNetwork\"\n",
    "    file['model_overview']['model_description']=\"\"\n",
    "    file['model_overview']['model_creator']=\"\"\n",
    "    file['model_overview']['model_owner']=\"\"\n",
    "    file['model_overview']['inference_environment']['container_image']=[event['model_image']]\n",
    "    file['business_details']['business_problem']=\"\"\n",
    "    file['business_details']['business_stakeholders']=\"\"\n",
    "    file['business_details']['line_of_business']=\"\"\n",
    "    file['intended_uses']['intended_uses']=\"\"\n",
    "    file['intended_uses']['explanations_for_risk_rating']=\"\"\n",
    "    file['intended_uses']['factors_affecting_model_efficiency']=\"Data Quality\"\n",
    "    file['intended_uses']['risk_rating']=\"Low\"\n",
    "    file['training_details']['training_job_details']['training_arn']=event['training_job_arn']\n",
    "    file['training_details']['training_job_details']['training_datasets']=event[\"input_data\"]\n",
    "    file['training_details']['training_job_details']['training_environment']['container_image']=[event['training_image_arn']]\n",
    "    file['training_details']['training_job_details']['hyper_parameters']=event[\"hyper_param\"]\n",
    "    file['training_details']['training_job_details']['training_metrics']=event[\"metrics\"]\n",
    "    file['evaluation_details']=[{\n",
    " 'datasets': [event[\"llm_metric_output\"]],\n",
    " 'name': event[\"llm_metric_name\"],\n",
    " 'metric_groups': [{'name': event[\"llm_metric_name\"],\n",
    "   'metric_data': event[\"stereotype\"]}],\n",
    " 'evaluation_observation': 'NA'}]\n",
    "\n",
    "\n",
    "    file=json.loads(str(file).replace(\"'\",'\"'))    \n",
    "    model_card_name=event['model_card']\n",
    "    \n",
    "    model_card_list=sm_client.list_model_cards(\n",
    "        NameContains=model_card_name,    \n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending'\n",
    "    )\n",
    "    if [x['ModelCardName'] for x in model_card_list['ModelCardSummaries'] if x['ModelCardName'] == model_card_name]:\n",
    "        sm_client.update_model_card(\n",
    "            ModelCardName=model_card_name,\n",
    "            Content=json.dumps(file),   \n",
    "            ModelCardStatus='PendingReview'\n",
    "        )\n",
    "    else:\n",
    "        \n",
    "        sm_client.create_model_card(\n",
    "            ModelCardName=model_card_name,    \n",
    "            Content=json.dumps(file),\n",
    "            ModelCardStatus='PendingReview',    \n",
    "        )\n",
    "    \n",
    "    \n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\" \"\"\"\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "    print(event)\n",
    "    # Getting the training job details to retrieve metrics information\n",
    "    training_job_details=sm_client.describe_training_job(TrainingJobName=event[\"training_job_name\"])\n",
    "    event[\"hyper_param\"]={key: value for key, value in training_job_details['HyperParameters'].items() if \"sagemaker\" not in key}\n",
    "    event[\"hyper_param\"]=[{\"name\": key, \"value\": value.strip('\"')} for key, value in event[\"hyper_param\"].items()]\n",
    "    event[\"input_data\"]=[f\"{x['ChannelName']} -> {x['DataSource']['S3DataSource']['S3Uri']}\" for x in training_job_details['InputDataConfig']]\n",
    "    \n",
    "    trial_c_list=sm_client.list_trial_components(\n",
    "        SortBy='CreationTime',\n",
    "        SortOrder='Descending',\n",
    "    )['TrialComponentSummaries']\n",
    "    trial_c_name=[x['TrialComponentName'] for x in trial_c_list if event['training_job_name'] in x['TrialComponentName']]\n",
    "    if not trial_c_name:\n",
    "        time.sleep(15)\n",
    "        trial_c_name=[x['TrialComponentName'] for x in trial_c_list if event['training_job_name'] in x['TrialComponentName']]\n",
    "    else: trial_c_name=trial_c_name[0]\n",
    "    metrics=sm_client.describe_trial_component(\n",
    "        TrialComponentName=trial_c_name)['Metrics']\n",
    "    event[\"metrics\"]=[{\"name\": item['MetricName'], \"value\": item['Min']} for item in metrics]\n",
    "    \n",
    "    # Getting the clarify job details to retrieve metrics information\n",
    "    eval_job_output=sm_client.describe_training_job(\n",
    "            TrainingJobName=event['eval_job_name']\n",
    "        )['OutputDataConfig']['S3OutputPath']+event['eval_job_name']+\"/output/output.tar.gz\"\n",
    "    s3client=boto3.client(\"s3\")\n",
    "    import io\n",
    "    import tarfile\n",
    "    bucket=eval_job_output.split(\"//\")[-1].split('/',1)[0]\n",
    "    key=eval_job_output.split(\"//\")[-1].split('/',1)[-1]\n",
    "    \n",
    "    s3_object = s3client.get_object(Bucket=bucket, Key=key)\n",
    "    wholefile = s3_object['Body'].read()\n",
    "    fileobj = io.BytesIO(wholefile)\n",
    "    tarf = tarfile.open(fileobj=fileobj)\n",
    "    names = tarf.getnames()\n",
    "    json_file_content = tarf.extractfile(names[0]).read()\n",
    "    json_file_content=json.loads(json_file_content.decode('utf-8'))[0]['category_scores']\n",
    "    \n",
    "    stereotypes_metrics=[{\"name\": item['name'], \"type\":\"number\",\"value\": item['scores'][0]['value']} for item in json_file_content]\n",
    "    event[\"stereotype\"]=stereotypes_metrics\n",
    "    event[\"llm_metric_output\"]=eval_job_output\n",
    "    event[\"llm_metric_name\"]=json_file_content[0]['scores'][0]['name']\n",
    "    \n",
    "    # Model card skeleton\n",
    "    model_card_template={'model_overview': {'model_name': '',\n",
    "  'model_id': '',\n",
    "  'model_artifact': [],\n",
    "  'model_version': 1,\n",
    "  'problem_type': '',\n",
    "  'algorithm_type': '',\n",
    "  'model_description': '',\n",
    "  'model_creator': '',\n",
    "  'model_owner': '',\n",
    "  'inference_environment': {'container_image': []}},\n",
    " 'business_details': {'business_problem': '',\n",
    "  'business_stakeholders': '',\n",
    "  'line_of_business': ''},\n",
    " 'intended_uses': {'intended_uses': '',\n",
    "  'explanations_for_risk_rating': '',\n",
    "  'factors_affecting_model_efficiency': '',\n",
    "  'risk_rating': ''},\n",
    " 'training_details': {'objective_function': {'function': {'function': 'Maximize',\n",
    "    'facet': 'Accuracy'}},\n",
    "  'training_job_details': {'training_arn': '',\n",
    "   'training_datasets': [],\n",
    "   'training_environment': {'container_image': []},\n",
    "   'hyper_parameters': [],\n",
    "   \n",
    "   'user_provided_hyper_parameters': []}},\n",
    "    'evaluation_details': [],     \n",
    "                        }\n",
    "    \n",
    "    model_card_template=json.loads(str(model_card_template).replace(\"'\",'\"'))\n",
    "    _create_model_card(model_card_template,event)\n",
    "\n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Created Model Card!\"),\n",
    "        \"other_key\": \"example_value\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfef21-fa55-4b10-91bb-aec03a49f2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the current time to define unique names for the resources created\n",
    "import time\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "function_name = \"sagemaker-model-card\" + current_time\n",
    "\n",
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
    "\n",
    "\n",
    "# Lambda helper class can be used to create the Lambda function\n",
    "func = Lambda( \n",
    "    function_name=function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"lambda_model_card.py\",\n",
    "    handler=\"lambda_model_card.lambda_handler\",\n",
    "    timeout=600,\n",
    "    memory_size=10240,\n",
    "    runtime='python3.10'\n",
    ")\n",
    "\n",
    "# The dictionary retured by the Lambda function is captured by LambdaOutput, each key in the dictionary corresponds to a\n",
    "# LambdaOutput\n",
    "\n",
    "output_param_1 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_3 = LambdaOutput(output_name=\"other_key\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "# The inputs provided to the Lambda function can be retrieved via the `event` object within the `lambda_handler` function\n",
    "# in the Lambda\n",
    "step_modelcard_lambda = LambdaStep(\n",
    "    name=\"LambdaStepModelCard\",\n",
    "    lambda_func=func,\n",
    "    inputs={\n",
    "        \"model_name\": model_name,\n",
    "        \"model_arn\":step_create_model.properties.ModelArn,\n",
    "        \"model_artifact\":step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        \"model_image\":step_create_model.properties.PrimaryContainer.Image,     \n",
    "        \"model_package_arn\": step_register.properties.ModelPackageArn,\n",
    "        \"model_group_name\":step_register.properties.ModelPackageGroupName,\n",
    "        \"model_package_version\":step_register.properties.ModelPackageVersion,\n",
    "        \"model_approval_status\":step_register.properties.ModelApprovalStatus,\n",
    "        \"role\": role,  \n",
    "        \"training_job_name\":step_train.properties.TrainingJobName,\n",
    "        \"training_job_arn\":step_train.properties.TrainingJobArn,\n",
    "        \"training_image_arn\":step_train.properties.AlgorithmSpecification.TrainingImage,\n",
    "        \"train_time\":step_train.properties.BillableTimeInSeconds,\n",
    "        \"instance_type\":step_train.properties.ResourceConfig.InstanceType,\n",
    "        \"instance_count\":step_train.properties.ResourceConfig.InstanceCount,        \n",
    "        \"model_card\":model_card_name     ,    \n",
    "        \"eval_job_name\": step_process.properties.TrainingJobName,\n",
    "    },\n",
    "    outputs=[output_param_1, output_param_2, output_param_3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421da1ce-398f-4e18-aa2e-9ae2c7528025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"LLama2TunePipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,  \n",
    "    parameters=[\n",
    "        training_instance_count,\n",
    "        endpoint_instance_type,\n",
    "        training_instance_type,\n",
    "        disable_output_compression,\n",
    "        intstruction_tune,\n",
    "        chat_dataset,\n",
    "        epoch,\n",
    "        quantization,\n",
    "        fsdp,\n",
    "        train_batch_size,\n",
    "        eval_batch_size,\n",
    "        learning_rate,\n",
    "        lora_r,\n",
    "        lora_alpha,\n",
    "        lora_dropout,\n",
    "        train_data_s3_path,\n",
    "        val_data_s3_path,\n",
    "        model_approval_status,\n",
    "        output_bucket,\n",
    "        model_package_group_name,\n",
    "        jumpstart_model_id,\n",
    "        jumpstart_model_version,\n",
    "        model_card_name,\n",
    "        stereotype_data_s3_path,\n",
    "        stereotype_dataset_name\n",
    "    ],\n",
    "    steps=[step_train,step_create_model,step_register, step_deploy_lambda, step_process,step_modelcard_lambda],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2faf24-e248-44a8-9561-87e543caa263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83717f02-b4b4-4842-8051-3329707116fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff18fb4-4708-4e52-bb6b-a028973d31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp crows-pairs_sample.jsonl s3://BUCKET/pipeline_trigger/ ## upload stereotype dataset to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ccd84-d8fe-4a99-8b43-2f83d23d05eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start( parameters=dict(\n",
    "        ModelPackageGroupName=\"LLama2-7b-FinanceTuned\",\n",
    "        ModelCardName=\"LLama2-7b-FinanceTuned\",\n",
    "    TrainDataS3Path=\"s3://jumpstart-cache-prod-us-east-1/training-datasets/sec_data/train/\",\n",
    "    ValidationDataS3Path=\"s3://jumpstart-cache-prod-us-east-1/training-datasets/sec_data/validation/\",\n",
    "    TrainingInstanceType=\"ml.g5.12xlarge\",\n",
    "    Epoch=\"1\",\n",
    "    ChatDataset=\"False\",\n",
    "    StereotypeDataS3Path=\"s3://BUCKET/crows-pairs_sample.jsonl\",  ## Get the dataset from https://github.com/aws/fmeval/blob/main/examples/crows-pairs_sample.jsonl\n",
    "    StereotypeDataName=\"crows-pairs_sample.jsonl\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b259b2b-8783-4e2b-9dbc-8bdc2812cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_config={\n",
    "    \"ModelPackageGroupName\":\"LLama2FinanceTuned\",\n",
    "    \"ModelCardName\":\"LLama2-7b-FinanceAdapted\",\n",
    "    \"TrainDataS3Path\":\"s3://jumpstart-cache-prod-us-east-1/training-datasets/sec_data/train/\",\n",
    "    \"ValidationDataS3Path\":\"s3://jumpstart-cache-prod-us-east-1/training-datasets/sec_data/validation/\",\n",
    "    \"TrainingInstanceType\":\"ml.g5.12xlarge\",\n",
    "    \"Epoch\":\"1\",\n",
    "    \"ChatDataset\":\"False\",\n",
    "    \"StereotypeDataS3Path\":\"s3://BUCKET/crows-pairs_sample.jsonl\", ## Get the dataset from https://github.com/aws/fmeval/blob/main/examples/crows-pairs_sample.jsonl\n",
    "    \"StereotypeDataName\":\"crows-pairs_sample.jsonl\"\n",
    "    }\n",
    "with open(\"config.json\",\"w\") as f:\n",
    "    json.dump(trigger_config,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb5f41-a8c8-479a-904a-0029ed69b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp config.json s3://BUCKET/pipeline_trigger/ ## create a lambda function which is triggered by an s3 bucket that has the function to execute a pipeline with the same pipeline name as above"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.c5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
